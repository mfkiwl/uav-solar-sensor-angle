{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f45298a",
   "metadata": {},
   "source": [
    "This notebook shows how to calculate all the angles. There are three major functions for the calculation. The <code>filter_sensor_points_to_cube_id</code> function returns only the sensor points that corresponds to one HSI cube. This significantly increases the efficiency and make the process faster. The second function <code>get_closest_sensor_point</code> returns a csv file that attaches the information from the closest sensor points for each raster pixel. The angles are calculated outside the functions. However, they can be converted into a function to form a loop for a number of HSI cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import distance\n",
    "from pvlib import solarposition\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8054cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the working directory\n",
    "os.chdir('YOUR WORKING DIRECTORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f163e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sensor_points_to_cube_id(sensor_filename, raster_filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function filters out only the sensor coordinates that align with\n",
    "    the cube boundary. Basically it relies on corresponding timestamp for\n",
    "    the cubes which is stored in a file \"frameindex_cubeid.txt\". The \n",
    "    corresponding UTC time of the timestamp is store id the \"imu_gps.txt\"\n",
    "    file. Based on that, only the in between coordinates are selected and\n",
    "    returned.\n",
    "    \n",
    "    Input:\n",
    "        - sensor_filename: (str) path of the sensor filename as ASCII format\n",
    "        - raster_filename: (str) path of the raster filename as csv format\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #######################################################################\n",
    "    # Read the sensor coordinates\n",
    "    sensor = pd.read_csv(sensor_filename, sep=\"\\\"\", header=None)\n",
    "    # Rename the columns\n",
    "    sensor.columns = ['Time', 'Lat_v', 'Lon_v']\n",
    "    \n",
    "    # Insert new columns for X and Y\n",
    "    sensor.insert(3, \"X_v\", 0)\n",
    "    sensor.insert(4, \"Y_v\", 0)\n",
    "\n",
    "    # Convert lat lon to X and Y in UTM 15N\n",
    "    transformer = Transformer.from_crs(4326, 32615)\n",
    "    Xv, Yv = transformer.transform(sensor.iloc[:, 1], sensor.iloc[:, 2])\n",
    "    sensor.loc[:, 'X_v'] = Xv\n",
    "    sensor.loc[:, 'Y_v'] = Yv\n",
    "    \n",
    "    # Convert the time string to a timestamp column\n",
    "    sensor['Time_UTC'] = pd.to_datetime(sensor['Time'])\n",
    "    # Drop the string time column\n",
    "    sensor.drop(columns=['Time'], inplace=True)\n",
    "    #######################################################################\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    # Get the cubeid from the raster_filename\n",
    "    cube_id = os.path.basename(raster_filename).split('_')[1]\n",
    "    # Generate the frame filename\n",
    "    frame_filename = os.path.join(os.path.dirname(raster_filename),\n",
    "                                  f'frameIndex_{cube_id}.txt')\n",
    "    # Generate the imu+gps filename\n",
    "    imu_filename = os.path.join(os.path.dirname(raster_filename),\n",
    "                                'imu_gps.txt')\n",
    "    \n",
    "    # Read frame and imu_gps files as df\n",
    "    frame = pd.read_csv(frame_filename, sep=\"\\t\", header=0)\n",
    "    imu = pd.read_csv(imu_filename, sep=\"\\t\", header=0,\n",
    "                      parse_dates=['Gps_UTC_Date&Time'])\n",
    "    #######################################################################\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    # Get the starting and ending frame timestamp\n",
    "    start_frame = frame.iloc[0, -1]\n",
    "    end_frame = frame.iloc[-1, -1]\n",
    "    \n",
    "    # Get the closest starting timestamp date\n",
    "    start_imu = pd.DatetimeIndex(imu.iloc[(imu['Timestamp']-start_frame).abs().argsort()[:1], 7])\n",
    "    # Add a 20s offset\n",
    "    start_imu = start_imu - pd.to_timedelta(20, unit='s')\n",
    "    # Get the string time information\n",
    "    start_imu = start_imu.strftime('%Y-%M-%d %H:%M:%-S')[0]\n",
    "\n",
    "    # Get the closest starting timestamp date\n",
    "    end_imu = pd.DatetimeIndex(imu.iloc[(imu['Timestamp']-end_frame).abs().argsort()[:1], 7])\n",
    "    # Add a 16s offset\n",
    "    end_imu = end_imu - pd.to_timedelta(16, unit='s')\n",
    "    # Get the string time information\n",
    "    end_imu = end_imu.strftime('%Y-%M-%d %H:%M:%-S')[0]\n",
    "    \n",
    "    # Filter the sensor df\n",
    "    sensor_filter = sensor[(sensor['Time_UTC'] >= start_imu) & (sensor['Time_UTC'] <= end_imu)]\n",
    "    #######################################################################\n",
    "    \n",
    "    return sensor_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6522e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_sensor_point(raster_filename, sensor_filename):\n",
    "\n",
    "    # Read the raster point csv file\n",
    "    raster = pd.read_csv(raster_filename, index_col=0)\n",
    "\n",
    "    # Split the rasters into 4 different parts\n",
    "    raster1, raster2, raster3, raster4 = np.array_split(raster, 4)\n",
    "    # Delete the raster\n",
    "    del raster\n",
    "\n",
    "    # Read the sensor shapefile\n",
    "    sensor = filter_sensor_points_to_cube_id(sensor_filename, raster_filename)\n",
    "    # Take only the X, Y\n",
    "    #sensor = sensor[['X_m', 'Y_m', 'Z']]\n",
    "    # Give the observations a new id\n",
    "    sensor['sensor_id'] = np.arange(0, sensor.shape[0])\n",
    "\n",
    "    # Create an empty list to hold the processed dfs\n",
    "    raster_sensor = []\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through every df\n",
    "    for raster_split in [raster1, raster2, raster3, raster4]:\n",
    "\n",
    "        # Get the X and Y from each dataframe\n",
    "        R = raster_split[['X_r', 'Y_r']].values\n",
    "        V = sensor[['X_v', 'Y_v']].values\n",
    "\n",
    "        # Calcualte the distance\n",
    "        dist = distance.cdist(R, V, 'euclidean')\n",
    "        # Calculate the minimum distance index\n",
    "        argmin_dist = np.argmin(dist, axis=1)\n",
    "\n",
    "        # Add the minimum sensor index to raster\n",
    "        raster_split['sensor_id'] = argmin_dist\n",
    "\n",
    "        # Join the sensor information to the raster split\n",
    "        raster_split_sensor = raster_split.join(sensor.set_index('sensor_id'), on='sensor_id')\n",
    "\n",
    "        # Add the df to the list\n",
    "        raster_sensor.append(raster_split_sensor)\n",
    "        \n",
    "        print(f\"Part {count+1} done\")\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "    # Create a pandas dataframe from the list of dfs\n",
    "    raster_sensor = pd.concat(raster_sensor)\n",
    "    # Drop the sensor_id\n",
    "    raster_sensor.drop(columns=['sensor_id'], inplace=True)\n",
    "    \n",
    "    return raster_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames\n",
    "sensor_filename = \"./Data/imu_gps.txt\"\n",
    "raster_filename = \"./Data/raw_0_rd_rf_or_pr_warp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740806c",
   "metadata": {},
   "source": [
    "Get the closest sensor points in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "raster_sensor = get_closest_sensor_point(raster_filename, sensor_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dataframe\n",
    "raster_sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8614f77",
   "metadata": {},
   "source": [
    "Function to calculate SZA (Solar Zenith Angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92494bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sensor_zenith_angle(R, V):\n",
    "    \n",
    "    return 90-np.degrees(np.arctan(50.0 / np.linalg.norm(R-V, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sza into the dataframe\n",
    "raster_sensor['VZA'] = calculate_sensor_zenith_angle(raster_sensor.iloc[:, 0:2].values,\n",
    "                                                     raster_sensor.iloc[:, 6:8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c272fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datetime index and localize it\n",
    "datetime_idx = pd.DatetimeIndex(raster_sensor['Time_UTC']).tz_convert('America/Chicago')\n",
    "# The local timezone should be changed based on the location\n",
    "\n",
    "# Equation of time\n",
    "equation_of_time = solarposition.equation_of_time_spencer71(datetime_idx.dayofyear).values\n",
    "\n",
    "# Hour angle in degrees\n",
    "ha = solarposition.hour_angle(datetime_idx,\n",
    "                              raster_sensor['Lon_r'].values,\n",
    "                              equation_of_time)\n",
    "\n",
    "# Solar declination in radians\n",
    "declination = solarposition.declination_cooper69(datetime_idx.dayofyear).values\n",
    "\n",
    "# Solar zenith angle in radians\n",
    "sza = solarposition.solar_zenith_analytical(np.radians(raster_sensor['Lat_r']),\n",
    "                                            np.radians(ha),\n",
    "                                            declination).values\n",
    "\n",
    "# Solar azimuth angle in radians\n",
    "saa = solarposition.solar_azimuth_analytical(np.radians(raster_sensor['Lat_r']),\n",
    "                                             np.radians(ha), declination, sza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the SZA and SAA to the dataframe, convert it to degrees\n",
    "raster_sensor['SZA'] = np.degrees(sza)\n",
    "raster_sensor['SAA'] = np.degrees(saa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcaa28",
   "metadata": {},
   "source": [
    "Function to calculate VAA (Viewing Azimuth Angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f572703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_viewing_azimuth_angle(X_v, Y_v, X_r, Y_r):\n",
    "\n",
    "    V = np.array([X_v, Y_v])\n",
    "    R = np.array([X_r, Y_r])\n",
    "\n",
    "    a = np.array([  0., 100.])\n",
    "    b = V - R\n",
    "    unit_a = a/np.linalg.norm(a)\n",
    "    unit_b = b/np.linalg.norm(b)\n",
    "    dot_prod = np.dot(unit_a, unit_b)\n",
    "\n",
    "    return np.degrees(np.arccos(np.clip(dot_prod, -1.0, 1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1af1be",
   "metadata": {},
   "source": [
    "Apply the VAA function to each row in the dataframe. Lambda function method was found to be the most efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "raster_sensor.loc[:, 'VAA'] = raster_sensor.apply(lambda row: calculate_viewing_azimuth_angle(row['X_v'],\n",
    "                                                         row['Y_v'],\n",
    "                                                         row['X_r'],\n",
    "                                                         row['Y_r'],), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe\n",
    "raster_sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56d6db",
   "metadata": {},
   "source": [
    "Convert the csv rows in to a ESRI shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_shape(df, X, Y, out_path):\n",
    "    geometry = [Point(xy) for xy in zip(df[X], df[Y])]\n",
    "    point_gdf = gpd.GeoDataFrame(df, crs=\"EPSG:32615\", geometry=geometry)\n",
    "    point_gdf.to_file(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_shape(raster_sensor.drop(columns=['Time_UTC']), 'X_r', 'Y_r', r\"F:\\danforthstudy\\temp\\angle_test.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8db59",
   "metadata": {},
   "source": [
    "The shapefile was interpolated using ArcGIS Natural Neighbor (https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/natural-neighbor.htm) tool. While doing the interpolation, 0.1 m was considered as the raster resolution. The outputs for the given datasaet are added in the <code>Outputs</code> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b42e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
